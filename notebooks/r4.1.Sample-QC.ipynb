{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample QC\n",
    "\n",
    "This notebook is a quick guide to how sketching algorithms can be used for sample QC. The particular emphasis is on getting from raw sequencing data to filtered reads, which we will then use in the next steps of our genomics workflow.\n",
    "\n",
    "> Note: many sketching algorithms can work with raw data, which contributes to the speed benefits of sketching. That being said, if we want more than just a quick and dirty analysis, it's always best to QC your data...\n",
    "\n",
    "We'll use the following sketching algorithms, implemented via some excellent open-source bioinformatics software:\n",
    "\n",
    "* MinHash\n",
    "* CountMin sketch\n",
    "* Bloom filter\n",
    "\n",
    "***\n",
    "\n",
    "## The data\n",
    "\n",
    "As mentioned in 4.1, we are looking at a suspected outbreak of *E.cloacae* in a hospital. We are using the sequence data collected during the [Reuter et al.](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4001082/) study. The following table contains the accessions for the isolates we need, I just grabbed this from the [supplementary file](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4001082/bin/NIHMS58061-supplement-Supplementary_Online_Content.pdf) and then added the ENA experiment and run IDs.\n",
    "\n",
    "|isolate name|patient ID|ENA biosample|ENA experiment|ENA run|\n",
    "|-|-|-|-|-|\n",
    "EC1a|EC1|ERS184249|ERX168346|ERR193657|\n",
    "EC2a|EC2|ERS184250|ERX168347|ERR193658|\n",
    "EC2b|EC2|ERS184251|ERX168341|ERR193652|\n",
    "EC3a|EC3|ERS184252|ERX168340|ERR193651|\n",
    "EC4a|EC4|ERS184245|ERX168345|ERR193656|\n",
    "EC5a|EC5|ERS184246|ERX168339|ERR193650|\n",
    "EC6a|EC6|ERS184247|ERX168343|ERR193654|\n",
    "EC7a|EC7|ERS184248|ERX168344|ERR193655|\n",
    "\n",
    "These samples correspond to whole genome sequence data for *E.cloacae* isolates, collected from several patients in the hospital during the suspected outbreak.\n",
    "\n",
    "To save us the pain of waiting for fastq-dump to collect the data, I have already downloaded it. For future reference though, use `fastq-dump` (part of [sra-tools](https://github.com/ncbi/sra-tools)) to download this data from the ENA. We could have sketched this download data stream, but as we know that we need this data for our analysis it is best to have it stored on disk. You'll see later how we can sketch a data stream from a download, evaluate these sketches to see if the data is helpful for our analysis, and then decide to store or discard it.\n",
    "\n",
    "The sequence data for these isolates is actually pretty poor quality - [FastQC](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/) showed the terminal 50 bases to be full of Ns and the quality dropped below Q20. So I ran Trimmomatic to clean the data, here is the command ran for one sample:\n",
    "\n",
    "```\n",
    "trimmomatic PE ERX168346_1.fastq ERX168346_2.fastq ERX168346_1-trimmed.fq ERX168346_1-se ERX168346_2-trimmed.fq ERX168346_2-se SLIDINGWINDOW:5:20 MINLEN:100\n",
    "```\n",
    "\n",
    "So, we now have quality checked, trimmed sequence data for each sample downloaded and ready to go. This is stored in `../data/reads`. To make things easier to follow, the following steps will be ran on just one of these samples. Feel free to update the code to run on all of them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check\n",
    "\n",
    "Are my samples what I think they are?!\n",
    "\n",
    "The study labelled these isolates as *E.cloacae*, let's use **MinHash** to check. We'll be using the excellent [sourmash](https://github.com/dib-lab/sourmash) software. The sourmash docs actually have loads of great examples and workflows - be sure to check them out too.\n",
    "\n",
    "\n",
    "* start with downloading a reference database of MinHash genome sketches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the pre-made MinHash database (courtesy of sourmash) containing all GenBank microbial genomes\n",
    "!wget -O genbank-k31.lca.json.gz https://osf.io/4f8n3/download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* next, create a MinHash sketch of the reads from one sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sketch the reads from a sample\n",
    "!sourmash compute --scaled 1000 -k 11,21,31 ../data/reads/ERX168346_*-trimmed.fq.gz --merge ERX168346 -o ERX168346.sketch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> the --scaled flag tells sourmash to decide the number of hashes to include in the MinHash sketch. Sourmash decides this based on the sequence length; it is effectively setting a compression ratio of 1000-to-1.\n",
    "\n",
    "> we have given 3 k-mer sizes with the `--k` flag, so will get 3 sketches\n",
    "\n",
    "> the --merge flag is to tell sourmash that we have 2 read files (paired end data). We will still get 3 sketches but each one will be made from both read files.\n",
    "\n",
    "* now we have sketched our sample, we can compare it to the reference sketches and check we have the organism we expect (e.cloacae!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the sketch of the reads against each sketch in the reference database\n",
    "!sourmash gather ERX168346.sketch genbank-k31.lca.json.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> note: the above command is sometimes killed by Binder as memory limits are exceed when the database is loaded. We can try an alternative approach that uses less memory:\n",
    "\n",
    "* perform a direct comparison between sample and the *e.cloacae* reference genome:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sourmash compute -k 11 --scaled 1000  ../data/GCF_000025565.1_ASM2556v1_genomic.fna.gz -o genome.sketch\n",
    "!sourmash search --containment genome.sketch ERX168346.sketch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the sketch from our sample matches the sketch of the *E.cloacae* reference genome - yay!\n",
    "\n",
    "It wasn't a complete match however, there is a little bit of a difference between the sketches. This is probably due to sequencing error. We will have a fair few unique k-mers in the sequencing data, which typically arise from errors during sequencing (but could also be from strain variation).\n",
    "\n",
    "Let's use some more sketching to investigate!\n",
    "\n",
    "\n",
    "## K-mer spectrum\n",
    "\n",
    "First off, let's check that our guess is right. Do we have a lot of unique k-mers? To answer this, we'll use the **Count-Min sketch** and another piece of software from Titus Brown et al. - [khmer](https://github.com/dib-lab/khmer).\n",
    "\n",
    "* begin by using a Count-Min sketch to create a k-mer count graph (the k-mer spectrum):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!abundance-dist-single.py -M 1e9 -k 21 -s ../data/reads/ERX168346_1-trimmed.fq.gz ERX168346.dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* plot the k-mer abundance against k-mer count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy\n",
    "from pylab import *\n",
    "dist1 = numpy.loadtxt('ERX168346.dist', skiprows=1, delimiter=',')\n",
    "plot(dist1[:,0], dist1[:,1])\n",
    "axis(xmax=200)\n",
    "title('k-mer abundance histogram')\n",
    "xlabel('k-mer abundance')\n",
    "ylabel('N k-mers with that abundance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a a lot unique k-mers in that plot. One reason to remove these is to reduce the amount of data we process in downstream analysis, which will reduce analysis time and take less memory (as there are fewer unique k-mers to hold in memory). That being said, it's not really necessary and removing them can have a negative impact on some analyses as we would be reducing coverage.\n",
    "\n",
    "So instead of removing them, let's first try to correct the sequence reads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read error correction using Bloom filters\n",
    "\n",
    "For this, we can use [lighter](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-014-0509-9). We need a bit of information first:\n",
    "\n",
    "* what size is the genome we have sequenced\n",
    "* how many reads do we have\n",
    "\n",
    "This information is used to calculate the sequencing coverage, this is then used to set the sampling fraction (alpha) so that it is inversely proportion to the depth of sequencing.\n",
    "\n",
    "We saw in the output of our earlier sourmash command that we have 574469 reads per file (read length ~140bp) for ERX168346. We also know that the genome size of *E.cloacae* is 5.31Mb. So our genome coverage from this sample is approximately 7X (which isn't great, but we did aggressively trim the data as the quality was poor).\n",
    "\n",
    "We calculate our sampling fraction for each file using the equation from the lighter paper: `7/coverage`.\n",
    "\n",
    "This means our sampling fraction is 2.13\n",
    "\n",
    "* now let's run lighter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!lighter -r ../data/reads/ERX168346_1-trimmed.fq.gz -k 17 5310000 2.13\n",
    "!lighter -r ../data/reads/ERX168346_2-trimmed.fq.gz -k 17 5310000 2.13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> lighter needs a k-mer size, the genome size and the alpha. Alpha is optional, but if you don't include it lighter will do an extra pass of your data to calculate it for you.\n",
    "\n",
    "Lighter corrected around 36000 bases - great! Let's now do some low-abundance k-mer trimming.\n",
    "\n",
    "\n",
    "## K-mer trimming using Count-Min sketch\n",
    "\n",
    "Back to the Count-Min sketch and khmer...\n",
    "\n",
    "* perform k-mer frequency based trimming on the corrected reads from lighter:\n",
    "\n",
    "> this takes a little while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!trim-low-abund.py -V -M 1e9 -C 3 -Z 10 -o ERX168346.corrected.trimmed.fq ERX168346_1-trimmed.cor.fq.gz ERX168346_2-trimmed.cor.fq.gz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* let's plot the k-mer spectrum again now the reads have been corrected and k-mer trimmed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!abundance-dist-single.py -M 1e9 -k 21 -s ERX168346.corrected.trimmed.fq ERX168346.dist\n",
    "\n",
    "dist1 = numpy.loadtxt('ERX168346.dist', skiprows=1, delimiter=',')\n",
    "plot(dist1[:,0], dist1[:,1])\n",
    "axis(xmax=200)\n",
    "title('k-mer abundance histogram')\n",
    "xlabel('k-mer abundance')\n",
    "ylabel('N k-mers with that abundance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we've managed to reduce the number of low abundance k-mers in our sample using sketching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "Let's move on to the next stage of the workflow: [resistome profiling](r4.3.Resistome-profiling.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
